\documentclass[a4paper, 11pt]{article}

%Comandos para configurar el idioma
\usepackage[spanish,activeacute]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc} %Necesario para el uso de las comillas latinas.
\usepackage{geometry}
\usepackage{graphicx}

%Importante que esta sea la última órden del preámbulo
\usepackage{hyperref}

\newcommand\fnurl[2]{%
\href{#2}{#1}\footnote{\url{#2}}%
}

\newcommand{\includecode}[2][c]{\lstinputlisting[caption=#2, escapechar=, style=custom#1]{#2}<!---->}

%Paquetes matemáticos
\usepackage{amsmath,amsfonts,amsthm}
\usepackage[all]{xy} %Para diagramas
\usepackage{enumerate} %Personalización de enumeraciones
\usepackage{tikz} %Dibujos

%Tipografía escalable
\usepackage{lmodern}
%Legibilidad
\usepackage{microtype}

%Código
\usepackage{listings}
\usepackage{color}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\definecolor{listinggray}{gray}{0.9}
\definecolor{lbcolor}{rgb}{0.9,0.9,0.9}
\lstset{
    backgroundcolor=\color{lbcolor},
    tabsize=4,
    rulecolor=,
    language=[GNU]C++,
    basicstyle=\scriptsize,
    upquote=true,
    aboveskip={1.5\baselineskip},
    columns=fixed,
    showstringspaces=false,
    extendedchars=false,
    breaklines=true,
    prebreak = \raisebox{0ex}[0ex][0ex]{\ensuremath{\hookleftarrow}},
    frame=single,
    numbers=left,
    showtabs=false,
    showspaces=false,
    showstringspaces=false,
    identifierstyle=\ttfamily,
    keywordstyle=\color[rgb]{0,0,1},
    commentstyle=\color[rgb]{0.026,0.112,0.095},
    stringstyle=\color[rgb]{0.627,0.126,0.941},
    numberstyle=\color[rgb]{0.205, 0.142, 0.73
%   \lstdefinestyle{C++}{language=C++,style=numbers}’.
}
\{
    backgroundcolor=\color{lbcolor},
    tabsize=4,
    language=C++,
    captionpos=b,
    tabsize=3,
    frame=lines,
    numbers=left,
    numberstyle=\tiny,
    numbersep=5pt,
    breaklines=true,
    showstringspaces=false,
    basicstyle=\footnotesize,
    %  identifierstyle=\color{magenta},
    keywordstyle=\color[rgb]{0,0,1},
    commentstyle=\color[rgb]{0.026,0.112,0.095}, % Darkgreen
    stringstyle=\color{red},
    escapeinside={(*@}{@*)}
}
% Slightly bigger margins than the latex defaults

\geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
\setlength{\parskip}{.5em} % por defecto el espacio entre párrafos es 0pt

\theoremstyle{definition}
\newtheorem{ejercicio}{Ejercicio}
\newtheorem{cuestion}{Cuestión}
\newtheorem*{solucion}{Solución}
\newtheorem*{bonus}{BONUS}

%%%%%%%% New sqrt
\usepackage{letltxmacro}
\makeatletter
\let\oldr@@t\r@@t
\def\r@@t#1#2{%
\setbox0=\hbox{$\oldr@@t#1{#2\,}$}\dimen0=\ht0
\advance\dimen0-0.2\ht0
\setbox2=\hbox{\vrule height\ht0 depth -\dimen0}%
{\box0\lower0.4pt\box2}}
\LetLtxMacro{\oldsqrt}{\sqrt}
\renewcommand*{\sqrt}[2][\ ]{\oldsqrt[#1]{#2} }
\makeatother

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\hypersetup{
    pdftitle={Informe de proyecto: Implementación del algoritmo de rectificación de Loop \& Zhang},
    pdfauthor={Antonio Álvarez Caballero, Alejandro García Montoro},
    unicode,
    breaklinks=true,  % so long urls are correctly broken across lines
    colorlinks=true,
    urlcolor=blue,
    linkcolor=blue,
    citecolor=darkgreen,
}

\title{Informe de proyecto: \\ Implementación del algoritmo de rectificación de Loop \& Zhang}
\author{Antonio Álvarez Caballero \\ Alejandro García Montoro \\
\href{mailto:analca3@correo.ugr.es}{analca3@correo.ugr.es} \\
\href{mailto:agarciamontoro@correo.ugr.es}{agarciamontoro@correo.ugr.es}}
\date{}
%%%%%%%%%%%%%%%%% FIN PREAMBULO %%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

    \maketitle

    \section{Descripción del problema}

    La rectificación de imágenes es el proceso de aplicar sendas homografías a un par de imágenes cuya geometría epipolar conocemos, de modo que las líneas epipolares queden horizontales, paralelas entre sí y con la misma coordenada vertical.

    La motivación de la rectificación es simple: al tener las líneas epipolares horizontales y con la misma coordenada vertical, buscar correspondencias entre las dos imágenes es mucho más fácil y eficiente; como sabemos que las correspondencias se encuentran en las mismas líneas epipolares, si suponemos que las imágenes están rectificadas basta buscar en la correspondiente fila de píxeles de la otra imagen, donde se encuentra la línea epipolar del punto que estemos considerando. Si las imágenes no estuvieran rectificadas, el tiempo de ejecución aumentaría considerablemente; la búsqueda en líneas inclinadas ---no paralelas con ninguno de los dos ejes--- es más compleja computacionalmente.

    Así, es claro que tener un par de imágenes rectificadas mejora la eficiencia de muchos de los algoritmos que precisan conocer la geometría epipolar y tienen que buscar correspondencias entre ambas imágenes. Por ejemplo, de esta situación se consigue la mejora computacional de los algoritmos que calculan mapas de disparidad, donde hay que medir el desplazamiento relativo entre los píxeles de una y otra imagen. Esta distancia relativa es lo que conocemos por \emph{disparidad}, y con esta información se puede reconstruir la profundidad incluso sin noción alguna de cámaras; basta un par de imágenes de una misma escena estática.

    Este proyecto implementa el método de rectificación propuesto por Charles Loop y Zhengyou Zhang en \cite{LoopZhang}.

    Su algoritmo es totalmente geométrico y no precisa conocimiento de las cámaras.
    Se consigue descomponiendo la homografía que se desea calcular para cada imagen en una proyección, una transformación euclídea y una cizalla, con especial cuidado en minimizar la distorsión del resultado con respecto a las imágenes originales.

    Es de hecho este último criterio el que hace del algoritmo una de las mejores soluciones actuales, ya que se consigue una rectificación que mantiene casi todas las propiedades de las imágenes originales.


    \section{Enfoque de la implementación y detalles de eficiencia}

    La implementación del algoritmo se basa en la descomposición de la homografía $H$ que se quiere obtener en las siguientes transformaciones:
    \begin{itemize}
        \item $H_p$: transformación proyectiva.
        \item $H_r$: transformación de semejanza.
        \item $H_s$: composición de una transformación de cizalla con un escalado y una traslación.
    \end{itemize}

    \subsection{Descomposición}
    Siguiendo la notación de \cite{LoopZhang}, sea $H$ la homografía siguiente:
    \[
    H =
    \begin{pmatrix}
        u_a & u_b & u_c \\
        v_a & v_b & v_c \\
        w_a & w_b & w_c
    \end{pmatrix}
    \]

    Si descomponemos $H$ en su parte proyectiva y afín ---y esta a su vez en una parte de semejanza y otra de cizalla---, obtenemos que
    \[
    H = H_s H_r H_p
    \]
    donde
    \[
    H_s =
    \begin{pmatrix}
        s_a & s_b & s_c \\
        0 & 1 & 0 \\
        0 & 0 & 1
    \end{pmatrix};\;\;
    H_r =
    \begin{pmatrix}
        v_b - v_c w_b & v_c w_a - v_a & 0 \\
        v_a - v_c w_a & v_b - v_c w_b & v_c \\
        0 & 0 & 1
    \end{pmatrix};\;\;
    H_p =
    \begin{pmatrix}
        1 & 0 & 0 \\
        0 & 1 & 0 \\
        w_a & w_b & 1
    \end{pmatrix}
    \]

    El cálculo de cada transformación se hace por separado, teniendo en cuenta las matrices calculadas anteriormente y criterios de minimización que se explicarán en cada subsección.

    Antes de todo este cálculo, sin embargo, hace falta calcular la geometría epipolar del par de imágenes, que el algoritmo supone conocida. Este paso previo se ha implementado buscando las correspondencias con un detector \lstinline{BRISK}, calculando la matriz fundamental con la llamada a la función \lstinline{findFundamentalMat} de \emph{OpenCV}---usando el algoritmo de los 8 puntos y \lstinline{RANSAC}--- y usando las llamadas a \lstinline{computeCorrespondEpilines} de la misma librería.

    \subsection{Transformación proyectiva}
    La transformación proyectiva lleva los epipolos $e$ y $e'$ al infinito, de manera que tras aplicar $H_p$ y $H'_p$, las líneas epipolares son ya paralelas.

    El cálculo de $w_a$, $w_b$ y  $w'_a$, $w'_b$ se basa en un criterio de minimización de la distorsión que puede resumirse en lo siguiente: buscamos unas transformaciones proyectivas $H_p$ y $H'_p$ que sean lo más cercanas que podamos a transformaciones afines.

    La idea es que las líneas $w = [w_a, w_b, 1]$ y $w' = [w'_a, w'_b, 1]$ transformen los puntos de la manera más compensada posible; es decir, dado un punto $p_i = [p_{i,u}, p_{i,v}, 1]$, la transformación $H_p$ lo transformará en el punto $[\frac{p_{i,u}}{\omega_i}, \frac{p_{i,v}}{\omega_i}, 1]$, donde los pesos $\omega_i$ pueden medir de alguna manera cuán proyectiva es nuestra transformación: si todos los pesos son idénticos, la transformación es afín.

    Buscamos por tanto unas líneas $w$ y $w'$ que consigan que los pesos $\omega_i$ se parezcan todo lo posible.

    Toda la discusión matemática se encuentra descrita en \cite{LoopZhang}, transformando el problema propuesto en la minimización de la siguiente expresión:
    \begin{equation}
        \frac{z^TAz}{z^TBz} + \frac{z^TA'z}{z^TB'z}
        \label{eq_minz}
    \end{equation}

    donde las matrices $A$, $B$ y sus homólogas con primas son conocidas y el vector $z = [\lambda, 1, 0]$ depende de un único parámetro $\lambda$ y es tal que $w = [e]_times z$ y $w' = Fz$.

    El cálculo de las matrices $A$, $B$, $A'$ y $B'$ depende únicamente de por qué matriz se multiplica: $[e]_\times$ si queremos calcular $A$ y $B$ o la matriz fundamental $F$ si queremos calcular $A$ y $B$:
    \begin{align*}
        A = [e]_\times^T P P^T [e]_\times && A' = F^T P' P'^T F \\
        B = [e]_\times^T p_c p_c^T [e]_\times && B' = F^T p_c' p_c'^T F
    \end{align*}

    Este cálculo se encuentra implementado en la siguiente función, donde la matriz \lstinline{mult_mat} representa $[e]_\times$ o $F$ según si queremos calcular las versiones normales o las primas:
    \begin{lstlisting}
    void obtainAB(const Mat &img, const Mat &mult_mat, Mat &A, Mat &B){
        int width = img.cols;
        int height = img.rows;

        int size = 3;

        Mat PPt = Mat::zeros(size, size, CV_64F);

        PPt.at<double>(0,0) = width*width - 1;
        PPt.at<double>(1,1) = height*height - 1;

        PPt *= (width*height) / 12.0;

        double w_1 = width - 1;
        double h_1 = height - 1;

        double values[3][3] = {
            {w_1*w_1, w_1*h_1, 2*w_1},
            {w_1*h_1, h_1*h_1, 2*h_1},
            {2*w_1, 2*h_1, 4}
        };

        Mat pcpct(size, size, CV_64F, values);

        pcpct /= 4;
        A = mult_mat.t() * PPt * mult_mat;
        B = mult_mat.t() * pcpct * mult_mat;
    }
    \end{lstlisting}

    Desarrollando la expresión descrita en \ref{eq_minz} obtenemos un polinomio en $\lambda$ cuyo mínimo es el valor que buscamos. Este mínimo se alcanza cuando su derivada con respecto a $\lambda$ es cero, así que todo nuestro problema se reduce a encontrar esta raíz.

    En \cite{LoopZhang} se da una primera aproximación a esta raíz, cuyo cálculo consiste en minimizar por separado ambos sumandos y tomar la media normalizada de las dos soluciones.

    De nuevo, allí se encuentra toda la discusión matemática, que se reduce a hacer lo siguiente para ambos sumandos:
    \begin{itemize}
        \item Hacer la descomposición de Cholesky de la matriz $A$ (resp. $A'$) ---que es simétrica y definida positiva--- para obtener una matriz triangular superior $D$ tal que $A = D^TD$  (resp. $A' = D'^TD'$).
        \item Encontrar el vector propio $y$ (resp. $y'$) asociado al mayor valor propio de $(D^{-1})^T B D^{-1}$ (resp. $(D'^{-1})^T B' D'^{-1}$).
        \item Tomar $z_1 = D^{-1}y$ (resp. $z_2 = D'^{-1}y'$)
    \end{itemize}

    Se toma entonces como primera aproximación a la raíz el siguiente vector:
    \[
    \frac{1}{2}\left(\frac{z_1}{\lVert z_1 \rVert} + \frac{z_2}{\lVert z_2 \rVert}\right)
    \]

    Toda este cálculo se encuentra implementado en la siguiente función:
    \begin{lstlisting}
    Vec3d getInitialGuess(Mat &A, Mat &B, Mat &Ap, Mat &Bp){

        Vec3d z_1 = maximize(A, B);
        Vec3d z_2 = maximize(Ap, Bp);

        return (normalize(z_1) + normalize(z_2))/2;
    }
    \end{lstlisting}

    donde el código realmente interesante está en \lstinline{maximize}:
    \begin{lstlisting}
    Vec3d maximize(Mat &A, Mat &B){
        Mat D; // Output of cholesky decomposition: upper triangular matrix.
        if( choleskyCustomDecomp(A, D) ){

            Mat D_inv = D.inv();

            Mat DBD = D_inv.t() * B * D_inv;

            // Solve the equations system using eigenvalue decomposition

            Mat eigenvalues, eigenvectors;
            eigen(DBD, eigenvalues, eigenvectors);

            // Take largest eigenvector
            Mat y = eigenvectors.row(0);

            Mat sol = D_inv*y.t();

            Vec3d res(sol.at<double>(0,0), sol.at<double>(1,0), sol.at<double>(2,0));

            return res;
        }

        // At this point, there is an error!
        Mat eigenvalues;
        eigen(A, eigenvalues);

        cout << "\n\n\n----------------------------- WARNING -----------------------" << endl;

        return Vec3d(0, 0, 0);
    }
    \end{lstlisting}

    Aunque \emph{OpenCV} pone a disposición del usuario una función que realiza el cálculo de la descomposición de Cholesky, su uso en este trabajo introducía errores de redondeo que impedían realizar la descomposición. En ocasiones calculaba valores propios muy cercanos a cero ---del orden de $10^{-5}$--- que tomaba como negativos, comprobando entonces erróneamente que la matriz $A$ no era definida positiva.

    Para evitar estos fallos y tener total control sobre los cálculos, decidimos implementar una función propia que calculara esta descomposición. La función es la que sigue, e implementa las fórmulas descritas en \cite{wikiChol}.
    \begin{lstlisting}
    bool choleskyCustomDecomp(const Mat &A, Mat &L){

      L = Mat::zeros(3,3,CV_64F);

      for (int i = 0; i < 3; i++){
        for (int j = 0; j <= i; j++){
          double sum = 0;
          for (int k = 0; k < j; k++){
            sum += L.at<double>(i,k) * L.at<double>(j,k);
          }

          L.at<double>(i,j) = A.at<double>(i,j) - sum;
          if (i == j){
            if (L.at<double>(i,j) < 0.0){
              if (L.at<double>(i,j) > -1e-5){
                L.at<double>(i,j) *= -1; (*@\label{comprobacion}@*)
              }
              else{
                return false;
              }
            }
            L.at<double>(i,j) = sqrt(L.at<double>(i,j));
          }
          else{
            L.at<double>(i,j) /= L.at<double>(j,j);
          }
        }
      }

      L = L.t();

      return true;
    }
    \end{lstlisting}

    La línea \ref{comprobacion} es la que evita los errores de redondeo descritos anteriormente. Cuando se intenta realizar la raíz cuadrada de un elemento, primero se comprueba si es negativo. En caso de serlo, se debe lanzar un fallo, a no ser que el valor sea muy cercano a cero; en esa situación, simplemente tomamos el valor opuesto y seguimos el algoritmo con naturalidad.

    En este punto del proceso tenemos una primera aproximación a la raíz que necesitamos, muy cercana a la real según \cite{LoopZhang} pero que puede ser optimizada.

    \subsection{Transformación de semejanza}
    Euclídea

    \subsection{Transformación de cizalla}

    \section{Experimentos realizados}

    Lola es muy guapa y adorable. V impone.

    \section{Valoración de resultados}

    Todo se ve de lujo

    \section{Conclusiones}

    Este algoritmo es pro. Mejor que el de OpenCV.

\end{document}
